"""
    Statistical analysis of datasets generated by detector.py
    Copyright (C) 2022  Bence Peter

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

    Contact email: ecneb2000@gmail.com
"""
import argparse
import logging
import time
import os
import tqdm
import cv2
import numpy as np
from pathlib import Path
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.cluster import OPTICS
from typing import List

from computer_vision_research.clustering import clustering_on_feature_vectors
from computer_vision_research.dataManagementClasses import TrackedObject
from utils.dataset import load_dataset
from utils.preprocessing import filter_trajectories
from utils.cluster import calc_cluster_centers, upscale_cluster_centers, make_4D_feature_vectors
sns.set_theme()

logging.basicConfig(level=logging.INFO)

def trafficHistogram(dataset: List[TrackedObject], labels: np.ndarray, output: str, bg_img: str):
    """Plot histogram about traffic flow.

    Args:
        dataset (List[TrackedObject]): Trajectory dataset. 
        output (str): Output directory path, where plots will be saved.
                      If output is None, plots will not be saved. 
        bg_img (str): Background image of the heatmap like plot.
    """
    from matplotlib import colors
    if output is not None:
        outpath = Path(output)
        if not outpath.exists():
            outpath.mkdir(parents=True)
    X = dataset
    Y = labels
    enter_cluster_center = calc_cluster_centers(X, Y, False)
    exit_cluster_center = calc_cluster_centers(X, Y, True)
    fig1, ax1 = plt.subplots(1,1,figsize=(15,10))
    ax1.set_title(f"{output} clusters histogram")
    classes = np.array(list(set(Y)))
    N, bins, patches = ax1.hist(Y, classes.shape[0], range=(classes.min()-0.5, classes.max()+0.5), edgecolor="black", align="mid", rwidth=0.7)
    print(N, bins, patches)
    if len(classes)==1:
        fracs = np.array([1.0])
    else:
        fracs = N / N.max()
    norm = colors.Normalize(fracs.min(), fracs.max())
    cmap = plt.cm.jet
    scalarMap = plt.cm.ScalarMappable(norm=norm, cmap=cmap)
    for thisfrac, thispatch in zip(fracs, patches):
        #TODO more vivid colors
        color = plt.cm.jet(norm(thisfrac)) # jet colors seem to be nice
        thispatch.set_facecolor(color)
    fig1.colorbar(plt.cm.ScalarMappable(norm, plt.cm.jet), ax=ax1, location='right')
    ax1.set_xlabel("Csoportok", fontdict={"fontsize": 20})
    ax1.set_ylabel("Autók száma", fontdict={"fontsize": 20})
    if output is not None:
        fig1Name = os.path.join(output, "histogram.png")
        fig1.savefig(fig1Name)
        logging.info(f"Fig1: \"{fig1Name}\"")
    if bg_img is not None:
        fig2, ax2 = plt.subplots(1,1,figsize=(15,10))
        ax2.set_title(f"{output} cluster heatmap")
        # Load background image, and make it a bit transparent
        bgImg = cv2.imread(bg_img)
        bgImg = cv2.cvtColor(bgImg, cv2.COLOR_RGB2BGR)
        bgImg = 255 - (255 - bgImg) * 0.5
        bgImg = bgImg.astype(np.uint8)
        mp = ax2.imshow(bgImg)
        # Upscale cluster centers to the size of the background image
        upscaled_enters = upscale_cluster_centers(enter_cluster_center, bgImg.shape[1], bgImg.shape[0])
        upscaled_exits = upscale_cluster_centers(exit_cluster_center, bgImg.shape[1], bgImg.shape[0])
        # Plot cluster vectors
        for p, q, thisfrac, cls in zip(upscaled_enters, upscaled_exits, fracs, classes):
            print(p, q, thisfrac, cls)
            color = plt.cm.jet(norm(thisfrac)) # jet colors seem to be nice
            colorVal = scalarMap.to_rgba(thisfrac)
            xx = np.vstack((p[0], q[0]))
            yy = np.vstack((p[1], q[1]))
            #ax2.plot(xx, yy, color=color, marker='o', linestyle='-')
            ax2.arrow(p[0], p[1], q[0]-p[0], q[1]-p[1], color=colorVal, width=1, head_width=10)
            #ax2.annotate(f"{cls}", (p[0], p[1]), color="black", fontsize=10, fontweigth=3)
            #ax2.annotate(f"{cls}", (p[0], p[1]), color="white", fontsize=10, fontweigth=1)
            # Slide the text a bit to the direction of the arrow
            vec = 0.7 * (np.array([q[0],q[1]]) - np.array([p[0],p[1]])) + np.array([p[0],p[1]])
            ax2.text(vec[0], vec[1], f"{cls}", color=colorVal, backgroundcolor="white", fontsize=14)
        fig2.colorbar(plt.cm.ScalarMappable(norm, plt.cm.jet), ax=ax2, location='bottom')
        if output is not None:
            fig2Name = os.path.join(output, "clusters.png")
            fig2.savefig(fig2Name)
            logging.info(f"Fig2: \"{fig2Name}\"")
    plt.show()
    plt.close()

def hourlyHistorgram(hourlyLabels, classes, output):
    sns.displot(data=hourlyLabels)
    plt.show()
    plt.savefig(Path(output).joinpath("hourlyHistogram.png"))
    plt.close()

def extractHourlyData(dataset: List[TrackedObject]):
    fps = 30
    fph = fps*60*60
    maxFrameNum = np.array([t.history[0].frameID for t in dataset]).max()
    hourNum = int(np.ceil([maxFrameNum/fph])[0])
    print(maxFrameNum, hourNum)
    hourlyData = np.zeros(shape=(hourNum, len(dataset)), dtype=TrackedObject)
    counter = np.zeros(shape=(hourNum), dtype=int)
    for i in range(len(dataset)):
        actHour = int(dataset[i].history[0].frameID//fph)
        hourlyData[actHour, counter[actHour]] = dataset[i]
    return hourlyData

def hourlyTable(paths, hourlyTracks, hourlyLabels, classes, output):
    """Plot table about hourly traffic flow.

    Args:
        paths (list): List of paths to the input files. 
        hourlyTracks (list): List of tracked objects for each hour. 
        hourlyLabels (list): List of labels for each hour.
        classes (list): List of classes. 
        output (str): Output directory path, where plots will be saved.
    """
    import pandas as pd
    sns.set(font_scale=1.5)
    hours = np.arange(len(paths))
    rows = ["{}-{}".format(i, i+1) for i in hours]
    #titles = [Path(p).stem for p in paths]
    df = pd.DataFrame()
    # set row names
    df = df.set_axis(labels=rows, axis=0)
    # count vehicles in each hour for each class
    hourlyCount = np.zeros(shape=(len(hourlyTracks), len(classes)))
    for i, tracks, labels in zip(range(len(hourlyTracks)), hourlyTracks, hourlyLabels):
        for t, l in zip(tracks, labels):
            if l >= 0:
                hourlyCount[i, l]+=1
    # set column names
    for cls in classes:
        df[cls] = np.array(hourlyCount[:, cls],dtype=int)
    cols = ["Csoport {}".format(i) for i in classes]
    df = df.set_axis(labels=cols, axis=1)
    # normalize by max of each row
    df_hourly_heatmap = (df.T - df.T.min()) / (df.T.max() - df.T.min())
    df_hourly_heatmap = df_hourly_heatmap.T
    # normalize by max of each column
    df_clusterly_heatmap = (df - df.min()) / (df.max() - df.min())
    print(df)
    print(df_hourly_heatmap)
    print(df_clusterly_heatmap)
    # Save to excel
    with pd.ExcelWriter(Path(output).joinpath("hourly_statistics_table.xlsx")) as writer:
        df.to_excel(writer, sheet_name="Hourly_Cluster_Stats")
    # Absolute values
    fig, ax = plt.subplots(figsize=(25,15))
    ax = sns.heatmap(df, annot=True, annot_kws={"size":20}, fmt="d", linecolor="black", linewidths=1, cmap="Reds")
    #ax.set(xlabel="Csoport (db)", ylabel="Időszak (óra)", kwargs={"size":20})
    ax.set_xlabel("Csoport (db)", fontdict={"size":20})
    ax.set_ylabel("Időszak (óra)", fontdict={"size":20})
    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)
    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, va="center")
    ax.set_title("Abszolút értékek")
    # Normalized by row
    fig2, ax2 = plt.subplots(figsize=(25,15))
    ax2 = sns.heatmap(df_hourly_heatmap, annot=True, annot_kws={"size":20}, fmt=".4f", linecolor="black", linewidths=1, cmap="Reds")
    #ax2.set(xlabel="Csoport (db)", ylabel="Időszak (óra)", kwargs={"size":20})
    ax2.set_xlabel("Csoport (db)", fontdict={"size":20})
    ax2.set_ylabel("Időszak (óra)", fontdict={"size":20})
    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=0)
    ax2.set_yticklabels(ax2.get_yticklabels(), rotation=0, va="center")
    ax2.set_title("Normalizált oránkénti értékek")
    # Normalized by column
    fig3, ax3 = plt.subplots(figsize=(25,15))
    ax3 = sns.heatmap(df_clusterly_heatmap, annot=True, annot_kws={"size":20}, fmt=".4f", linecolor="black", linewidths=1, cmap="Reds")
    #ax3.set(xlabel="Csoport (db)", ylabel="Időszak (óra)", kwargs={"size":20})
    ax3.set_xlabel("Csoport (db)", fontdict={"size":20})
    ax3.set_ylabel("Időszak (óra)", fontdict={"size":20})
    ax3.set_xticklabels(ax3.get_xticklabels(), rotation=0)
    ax3.set_yticklabels(ax3.get_yticklabels(), rotation=0, va="center")
    ax3.set_title("Normalizált irányonkénti értékek")
    # Save figures
    fig.savefig(Path(output).joinpath("heatmap_abs.png"))
    fig2.savefig(Path(output).joinpath("heatmap_hourly_norm.png"))
    fig3.savefig(Path(output).joinpath("heatmap_cluster_norm.png"))
    plt.close()

def printSamplesToExcel(tracks, output, n_samples=10):
    """Print sample trajectories to excel file.

    Args:
        tracks (list): List of tracked objects.
        output (str): Output directory path, where plots will be saved.
    """
    import pandas as pd
    data = {"Normalizált belépő X": [], "Normalizált belépő Y": [], "Normalizált kilépő X": [], "Normalizált kilépő Y": []}
    indexes = []
    df = pd.DataFrame(data=data)
    for i, t in enumerate(tracks):
        if i >= n_samples:
            break
        df.loc[-1] = [t.history_X[0], t.history_Y[0], t.history_X[-1], t.history_Y[-1]]
        df.index = df.index + 1
        indexes.append("Trajektória {}".format(t.objID))
    df.index = indexes
    df.sort_index(inplace=True)
    print(df)
    with pd.ExcelWriter(Path(output).joinpath("sample_trajectories.xlsx")) as writer:
        df.to_excel(writer, sheet_name="Sample_Trajectories")

def trafficHistogramModule(args):
    logging.info("Traffic histogram module started")
    start = time.time()
    tracks = load_dataset(args.database[0])
    if not args.filtered:
        tracks_filtered = filter_trajectories(tracks, 0.7)
    else:
        tracks_filtered = tracks
    X = make_4D_feature_vectors(tracks_filtered)
    _, labels = clustering_on_feature_vectors(
        X, OPTICS, 
        min_samples=args.min_samples,
        max_eps=args.max_eps,
        xi=args.xi,
        p=args.p_norm
    )
    Y = labels[labels > -1]
    X = tracks_filtered[labels > -1]
    trafficHistogram(tracks_filtered, 
                     Y,
                     args.output,
                     args.bg_img,
                     min_samples=args.min_samples,
                     max_eps=args.max_eps,
                     xi=args.xi,
                     p=args.p_norm)
    logging.info(f"Traffic histogram module ran for {time.time()-start} seconds")

def hourlyStatisticsModule(args):
    logging.info("Traffic hourly statistics module started")
    start = time.time()

    tracksHourly = [] 
    labelsHourly = []
    datasets = []
    datasetPath = Path(args.database[0])
    if datasetPath.is_dir():
        datasets = [ds for ds in datasetPath.glob("*.joblib")]
        datasets = sorted(datasets)
        for ds in datasets:
            if args.filtered:
                if "filtered" in ds.name:
                    print(ds)
                    tmpTracks = load_dataset(ds)
                    tracksHourly.append(tmpTracks)
                    print(len(tmpTracks))
            else:
                if "filtered" not in ds.name:
                    tmpTracks = load_dataset(ds)
                    tracksHourly.append(filter_trajectories(tmpTracks, 0.7))
                    datasets.append(str(ds))
            labelsHourly.append([])
    else:
        for ds in args.database:
            tmpTracks = load_dataset(ds)
            if not args.filtered:
                tracksHourly.append(filter_trajectories(tmpTracks, 0.7))
                datasets.append(ds)
            else:
                tracksHourly.append(tmpTracks)
                datasets.append(ds)
            labelsHourly.append([])
    tracksHourly = np.array(tracksHourly, dtype=TrackedObject)
    dataset = np.array([], dtype=TrackedObject)
    for tracks in tracksHourly:
        dataset = np.append(dataset, tracks, axis=0)
    printSamplesToExcel(dataset, args.output)
    uidSamples = np.arange(start=1, stop=len(dataset)+1) # generate unique ids for all the tracks
    uidHourly = np.zeros(shape=(len(tracksHourly),len(dataset)), dtype=int) # create the hourly uid matrix
    uidHourly[0,:len(tracksHourly[0])] = uidSamples[0:len(tracksHourly[0])] # init first row of uid matrix
    if uidHourly.shape[0] > 1: # if there is more than 1 hour to analyze do this
        for i in range(1, uidHourly.shape[0]): # insert uids to the corresponding hours
            end = np.array([len(tracksHourly[j]) for j in range(i+1)],dtype=int).sum()
            begin = np.array([len(tracksHourly[j]) for j in range(i)],dtype=int).sum()
            uidHourly[i,:len(tracksHourly[i])] = uidSamples[begin:end]

    feature_vectors = make_4D_feature_vectors(dataset)
    cls, labels = clustering_on_feature_vectors(
        X=feature_vectors, 
        estimator=OPTICS, 
        n_jobs=args.n_jobs,
        min_samples=args.min_samples,
        max_eps=args.max_eps,
        xi=args.xi,
        p=args.p_norm
    )
    Y = labels[labels > -1]
    X = dataset[labels > -1]
    uidSamplesClustered = uidSamples[labels > -1]
    classes = list(set(Y))
    print(f"Classes: {classes}") # print classes resulting from clustering

    trafficHistogram(X, Y,
                    args.output,
                    args.bg_img)

    uidHourlyClustered = np.zeros_like(uidHourly, dtype=int)
    tracksHourlyClustered = np.zeros_like(uidHourly,dtype=int).astype(object)
    labelsHourlyClustered = np.ones_like(uidHourly,dtype=int)*-1
    for i in range(len(uidHourly)):
        for j in tqdm.tqdm(range(len(np.trim_zeros(uidHourly[i], 'b')))):
            for k in range(len(uidSamplesClustered)):
                if uidHourly[i,j]==uidSamplesClustered[k]:
                    uidHourlyClustered[i,j] = uidSamplesClustered[k]
                    labelsHourlyClustered[i,j] = labels[k]
                    tracksHourlyClustered[i,j] = dataset[k]
                    break
    print(tracksHourlyClustered.shape)
    print(labelsHourlyClustered.shape)
    hourlyTable(datasets, tracksHourlyClustered, labelsHourlyClustered, classes, args.output)
    # hourlyHistorgram(labelsHourlyClustered, classes, args.output)
    logging.info(f"Traffic hourly statistics module ran for {time.time()-start} seconds")

def trafficStatisticTable(args):
    logging.info("Traffic histogram module started")
    start = time.time()
    tracks = load_dataset(args.database[0])
    if not args.filtered:
        tracks_filtered = filter_trajectories(tracks, 0.7)
    else:
        tracks_filtered = tracks
   #TODO statistical table about clusters

def main():
    argparser = argparse.ArgumentParser("Traffic statistics plotter")
    argparser.add_argument("-db", "--database", nargs='+', help="Database path.")
    argparser.add_argument("-o", "--output", help="Output directory path of the plots.")
    argparser.add_argument("--filtered", action="store_true", default=False, help="If dataset is already filtered use this flag.")
    argparser.add_argument("--n_jobs", type=int, default=16, help="Number of processed to run.")
    subParser = argparser.add_subparsers(help="Plot statistical data about the traffic data collected in runtime.")

    clusterHistogram = subParser.add_parser("histogram", help="Plot histogram of clusters.")
    clusterHistogram.add_argument("--min_samples", default=20, type=int, help="OPTICS min samples param.")
    clusterHistogram.add_argument("--max_eps", type=float, default=0.2, help="OPTICS max epsilon distance param.")
    clusterHistogram.add_argument("--xi", type=float, default=0.15, help="OPTICS xi param.")
    clusterHistogram.add_argument("--p_norm", type=int, default=2, help="OPTICS p norm param.")
    clusterHistogram.add_argument("--bg_img", help="Background image path.")
    clusterHistogram.set_defaults(func=trafficHistogramModule)

    hourlyClusterStats = subParser.add_parser("hourly", help="Plot hourly statistic.")
    hourlyClusterStats.add_argument("--min_samples", default=20, type=int, help="OPTICS min samples param.")
    hourlyClusterStats.add_argument("--max_eps", type=float, default=0.2, help="OPTICS max epsilon distance param.")
    hourlyClusterStats.add_argument("--xi", type=float, default=0.15, help="OPTICS xi param.")
    hourlyClusterStats.add_argument("--p_norm", type=int, default=2, help="OPTICS p norm param.")
    hourlyClusterStats.add_argument("--bg_img", help="Background image path.")
    hourlyClusterStats.set_defaults(func=hourlyStatisticsModule)

    args = argparser.parse_args()
    args.func(args)

if __name__ == "__main__":
    main()