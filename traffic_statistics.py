"""
    Statistical analysis of datasets generated by detector.py
    Copyright (C) 2022  Bence Peter

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

    Contact email: ecneb2000@gmail.com
"""
import argparse
import logging
import time
import os
import tqdm
import numpy as np
from pathlib import Path
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.cluster import OPTICS
from typing import List
from processing_utils import (
    load_joblib_tracks, 
    filter_trajectories, 
    make_4D_feature_vectors,
    calc_cluster_centers,
    upscale_cluster_centers
)
from clustering import clustering_on_feature_vectors
from dataManagementClasses import TrackedObject
sns.set_theme()

logging.basicConfig(level=logging.INFO)

def trafficHistogram(dataset: List[TrackedObject], labels: np.ndarray, output: str, bg_img: str):
    """Plot histogram about traffic flow.

    Args:
        dataset (List[TrackedObject]): Trajectory dataset. 
        output (str): Output directory path, where plots will be saved.
                      If output is None, plots will not be saved. 
        bg_img (str): Background image of the heatmap like plot.
    """
    from matplotlib import colors
    if output is not None:
        outpath = Path(output)
        if not outpath.exists():
            outpath.mkdir(parents=True)
    X = dataset
    Y = labels
    enter_cluster_center = calc_cluster_centers(X, Y, False)
    exit_cluster_center = calc_cluster_centers(X, Y, True)
    fig1, ax1 = plt.subplots(1,1,figsize=(15,15))
    ax1.set_title(f"{output} clusters histogram")
    classes = np.array(list(set(Y)))
    N, bins, patches = ax1.hist(Y, classes-0.5, align="mid", range=(classes.min(), classes.max()), edgecolor="black")
    if len(classes)==1:
        fracs = np.array([1.0])
    else:
        fracs = N / N.max()
    norm = colors.Normalize(fracs.min(), fracs.max())
    cmap = plt.cm.jet
    scalarMap = plt.cm.ScalarMappable(norm=norm, cmap=cmap)
    for thisfrac, thispatch in zip(fracs, patches):
        #TODO more vivid colors
        color = plt.cm.jet(norm(thisfrac)) # jet colors seem to be nice
        thispatch.set_facecolor(color)
    fig1.colorbar(plt.cm.ScalarMappable(norm, plt.cm.jet), ax=ax1, location='right')
    if output is not None:
        fig1Name = os.path.join(output, "histogram.png")
        fig1.savefig(fig1Name)
        logging.info(f"Fig1: \"{fig1Name}\"")
    if bg_img is not None:
        fig2, ax2 = plt.subplots(1,1,figsize=(15,15))
        ax2.set_title(f"{output} cluster heatmap")
        bgImg = plt.imread(bg_img)
        mp = ax2.imshow(bgImg)
        upscaled_enters = upscale_cluster_centers(enter_cluster_center, bgImg.shape[1], bgImg.shape[0])
        upscaled_exits = upscale_cluster_centers(exit_cluster_center, bgImg.shape[1], bgImg.shape[0])
        for p, q, thisfrac in zip(upscaled_enters, upscaled_exits, fracs):
            color = plt.cm.jet(norm(thisfrac)) # jet colors seem to be nice
            colorVal = scalarMap.to_rgba(thisfrac)
            xx = np.vstack((p[0], q[0]))
            yy = np.vstack((p[1], q[1]))
            #ax2.plot(xx, yy, color=color, marker='o', linestyle='-')
            ax2.arrow(p[0], p[1], q[0]-p[0], q[1]-p[1], color=colorVal, width=1, head_width=10)
        fig2.colorbar(plt.cm.ScalarMappable(norm, plt.cm.jet), ax=ax2, location='bottom')
        if output is not None:
            fig2Name = os.path.join(output, "clusters.png")
            fig2.savefig(fig2Name)
            logging.info(f"Fig2: \"{fig2Name}\"")
    plt.show()
    plt.close()

def hourlyHistorgram(hourlyLabels, classes, output):
    sns.displot(data=hourlyLabels)
    plt.show()
    plt.savefig(Path(output).joinpath("hourlyHistogram.png"))
    plt.close()

def extractHourlyData(dataset: List[TrackedObject]):
    fps = 30
    fph = fps*60*60
    maxFrameNum = np.array([t.history[0].frameID for t in dataset]).max()
    hourNum = int(np.ceil([maxFrameNum/fph])[0])
    print(maxFrameNum, hourNum)
    hourlyData = np.zeros(shape=(hourNum, len(dataset)), dtype=TrackedObject)
    counter = np.zeros(shape=(hourNum), dtype=int)
    for i in range(len(dataset)):
        actHour = int(dataset[i].history[0].frameID//fph)
        hourlyData[actHour, counter[actHour]] = dataset[i]
    return hourlyData

def hourlyTable(paths, hourlyTracks, hourlyLabels, classes, output):
    import pandas as pd
    hours = np.arange(len(paths))
    titles = [Path(p).stem for p in paths]
    df = pd.DataFrame({"Datetime":titles}, dtype=object)
    df = df.set_index("Datetime")
    hourlyCount = np.zeros(shape=(len(hourlyTracks), len(classes)))
    for i, tracks, labels in zip(range(len(hourlyTracks)), hourlyTracks, hourlyLabels):
        for t, l in zip(tracks, labels):
            if l >= 0:
                hourlyCount[i, l]+=1
    for cls in classes:
        df[cls] = np.array(hourlyCount[:, cls],dtype=int)
    print(df)
    fig, ax = plt.subplots(figsize=(45,15))
    ax = sns.heatmap(df, annot=True, fmt="d", linecolor="black", linewidths=1, cmap="Reds")
    ax.set(xlabel="Clusters", ylabel="Hours")
    plt.yticks(rotation=0)
    plt.show()
    plt.savefig(Path(output).joinpath("heatmap.png"))
    plt.close()

def trafficHistogramModule(args):
    logging.info("Traffic histogram module started")
    start = time.time()
    tracks = load_joblib_tracks(args.database[0])
    if not args.filtered:
        tracks_filtered = filter_trajectories(tracks, 0.7)
    else:
        tracks_filtered = tracks
    X = make_4D_feature_vectors(tracks_filtered)
    _, labels = clustering_on_feature_vectors(
        X, OPTICS, 
        min_samples=args.min_samples,
        max_eps=args.max_eps,
        xi=args.xi,
        p=args.p_norm
    )
    Y = labels[labels > -1]
    X = tracks_filtered[labels > -1]
    trafficHistogram(tracks_filtered, 
                     Y,
                     args.output,
                     args.bg_img,
                     min_samples=args.min_samples,
                     max_eps=args.max_eps,
                     xi=args.xi,
                     p=args.p_norm)
    logging.info(f"Traffic histogram module ran for {time.time()-start} seconds")

def hourlyStatisticsModule(args):
    logging.info("Traffic hourly statistics module started")
    start = time.time()

    tracksHourly = [] 
    labelsHourly = []
    datasets = []
    datasetPath = Path(args.database[0])
    if datasetPath.is_dir():
        datasets = [ds for ds in datasetPath.glob("*.joblib")]
        datasets = sorted(datasets)
        for ds in datasets:
            if args.filtered:
                if "filtered" in ds.name:
                    print(ds)
                    tmpTracks = load_joblib_tracks(ds)
                    tracksHourly.append(tmpTracks)
                    print(len(tmpTracks))
            else:
                if "filtered" not in ds.name:
                    tmpTracks = load_joblib_tracks(ds)
                    tracksHourly.append(filter_trajectories(tmpTracks, 0.7))
                    datasets.append(str(ds))
            labelsHourly.append([])
    else:
        for ds in args.database:
            tmpTracks = load_joblib_tracks(ds)
            if not args.filtered:
                tracksHourly.append(filter_trajectories(tmpTracks, 0.7))
                datasets.append(ds)
            else:
                tracksHourly.append(tmpTracks)
                datasets.append(ds)
            labelsHourly.append([])
    tracksHourly = np.array(tracksHourly, dtype=TrackedObject)
    dataset = np.array([], dtype=TrackedObject)
    for tracks in tracksHourly:
        dataset = np.append(dataset, tracks, axis=0)
    print(dataset.shape)
    uidSamples = np.arange(start=1, stop=len(dataset)+1) # generate unique ids for all the tracks
    uidHourly = np.zeros(shape=(len(tracksHourly),len(dataset)), dtype=int) # create the hourly uid matrix
    uidHourly[0,:len(tracksHourly[0])] = uidSamples[0:len(tracksHourly[0])] # init first row of uid matrix
    if uidHourly.shape[0] > 1: # if there is more than 1 hour to analyze do this
        for i in range(1, uidHourly.shape[0]): # insert uids to the corresponding hours
            end = np.array([len(tracksHourly[j]) for j in range(i+1)],dtype=int).sum()
            begin = np.array([len(tracksHourly[j]) for j in range(i)],dtype=int).sum()
            uidHourly[i,:len(tracksHourly[i])] = uidSamples[begin:end]

    feature_vectors = make_4D_feature_vectors(dataset)
    cls, labels = clustering_on_feature_vectors(
        X=feature_vectors, 
        estimator=OPTICS, 
        n_jobs=args.n_jobs,
        min_samples=args.min_samples,
        max_eps=args.max_eps,
        xi=args.xi,
        p=args.p_norm
    )
    Y = labels[labels > -1]
    X = dataset[labels > -1]
    uidSamplesClustered = uidSamples[labels > -1]
    classes = list(set(Y))
    print(f"Classes: {classes}") # print classes resulting from clustering

    trafficHistogram(X, Y,
                    args.output,
                    args.bg_img)

    uidHourlyClustered = np.zeros_like(uidHourly, dtype=int)
    tracksHourlyClustered = np.zeros_like(uidHourly,dtype=int).astype(object)
    labelsHourlyClustered = np.ones_like(uidHourly,dtype=int)*-1
    for i in range(len(uidHourly)):
        for j in tqdm.tqdm(range(len(uidHourly[i]))):
            for k in range(len(uidSamplesClustered)):
                if uidHourly[i,j]==uidSamplesClustered[k]:
                    uidHourlyClustered[i,j] = uidSamplesClustered[k]
                    labelsHourlyClustered[i,j] = labels[k]
                    tracksHourlyClustered[i,j] = dataset[k]
                    break
    print(tracksHourlyClustered.shape)
    print(labelsHourlyClustered.shape)
    hourlyTable(datasets, tracksHourlyClustered, labelsHourlyClustered, classes, args.output)
    # hourlyHistorgram(labelsHourlyClustered, classes, args.output)
    logging.info(f"Traffic hourly statistics module ran for {time.time()-start} seconds")

def trafficStatisticTable(args):
    logging.info("Traffic histogram module started")
    start = time.time()
    tracks = load_joblib_tracks(args.database[0])
    if not args.filtered:
        tracks_filtered = filter_trajectories(tracks, 0.7)
    else:
        tracks_filtered = tracks
   #TODO statistical table about clusters

def main():
    argparser = argparse.ArgumentParser("Traffic statistics plotter")
    argparser.add_argument("-db", "--database", nargs='+', help="Database path.")
    argparser.add_argument("-o", "--output", help="Output directory path of the plots.")
    argparser.add_argument("--filtered", action="store_true", default=False, help="If dataset is already filtered use this flag.")
    argparser.add_argument("--n_jobs", type=int, default=16, help="Number of processed to run.")
    subParser = argparser.add_subparsers(help="Plot statistical data about the traffic data collected in runtime.")

    clusterHistogram = subParser.add_parser("histogram", help="Plot histogram of clusters.")
    clusterHistogram.add_argument("--min_samples", default=20, type=int, help="OPTICS min samples param.")
    clusterHistogram.add_argument("--max_eps", type=float, default=0.2, help="OPTICS max epsilon distance param.")
    clusterHistogram.add_argument("--xi", type=float, default=0.15, help="OPTICS xi param.")
    clusterHistogram.add_argument("--p_norm", type=int, default=2, help="OPTICS p norm param.")
    clusterHistogram.add_argument("--bg_img", help="Background image path.")
    clusterHistogram.set_defaults(func=trafficHistogramModule)

    hourlyClusterStats = subParser.add_parser("hourly", help="Plot hourly statistic.")
    hourlyClusterStats.add_argument("--min_samples", default=20, type=int, help="OPTICS min samples param.")
    hourlyClusterStats.add_argument("--max_eps", type=float, default=0.2, help="OPTICS max epsilon distance param.")
    hourlyClusterStats.add_argument("--xi", type=float, default=0.15, help="OPTICS xi param.")
    hourlyClusterStats.add_argument("--p_norm", type=int, default=2, help="OPTICS p norm param.")
    hourlyClusterStats.add_argument("--bg_img", help="Background image path.")
    hourlyClusterStats.set_defaults(func=hourlyStatisticsModule)

    args = argparser.parse_args()
    args.func(args)

if __name__ == "__main__":
    main()